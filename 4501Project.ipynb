{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4c5a136-e872-4846-9965-9ddc5251a0b3",
   "metadata": {},
   "source": [
    "# NYC Apartment Search\n",
    "\n",
    "_[Project prompt](https://docs.google.com/document/d/1BYVyFBDcTywdUlanH0ysfOrNWPgl7UkqXA7NeewTzxA/edit#heading=h.bpxu7uvknnbk)_\n",
    "\n",
    "## Problem Overview\n",
    "Let’s say your apartment lease is ending at the end of the year, and you need to find a new apartment. There are a lot of criteria you can use to help find a neighborhood you’d like to live in. One thing you care a lot about is a quiet neighborhood with a lot of greenery. \n",
    "\n",
    "Using NYC Open Data datasets and Zillow’s historic monthly rent averages, you will be creating a single Jupyter notebook to download, clean, and store data, as well as defining a set of SQL queries and visualizations to help answer questions of yours in search of a great area to live within your budget.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf11fa0-4684-4f5e-8048-0f4cc5f4f243",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f675d4b-794e-407c-aac9-b85c4a3975d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import statements needed for the project\n",
    "import math\n",
    "from datetime import datetime, timedelta\n",
    "from datetime import date\n",
    "import numpy as np\n",
    "import json\n",
    "import pathlib\n",
    "import urllib.parse\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import requests\n",
    "import shapely\n",
    "import sqlalchemy as db\n",
    "import os\n",
    "import folium\n",
    "\n",
    "from shapely.geometry import Point\n",
    "from sqlalchemy.orm import declarative_base\n",
    "from sqlalchemy import create_engine, MetaData, Table, Column, Integer, String, Float, TIMESTAMP, Date, text\n",
    "\n",
    "import re\n",
    "import geoalchemy2 as gdb \n",
    "from geoalchemy2 import Geometry, WKTElement\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "import geoplot as gplt\n",
    "import geoplot.crs as gcrs\n",
    "from pathlib import PosixPath\n",
    "from pyproj import CRS, Transformer\n",
    "from shapely.ops import transform\n",
    "from shapely.geometry import Point\n",
    "from shapely.wkb import dumps\n",
    "from pathlib import Path\n",
    "import geodatasets\n",
    "import contextily as cx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70a62277-51cf-48a2-81d2-9b2127088a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants you might need; some have been added for you\n",
    "\n",
    "# Where data files will be read from/written to - this should already exist\n",
    "DATA_DIR = pathlib.Path(\"data\")\n",
    "COMPLAINTS_DATE_DIR =  pathlib.Path(\"data/311_data\")\n",
    "ZIPCODE_DATA_FILE = DATA_DIR /\"nyc_zipcodes.shp\"\n",
    "ZILLOW_DATA_FILE = DATA_DIR / \"zillow_rent_data.csv\"\n",
    "\n",
    "# Token Related Information Variable\n",
    "APP_TOKEN = \"WZUCCEUBzIBROFj20iUxnoyQV\"\n",
    "BASE_NYC_DATA_URL = \"https://data.cityofnewyork.us/resource/\"\n",
    "NYC_DATA_311 = \"erm2-nwe9.json\"\n",
    "NYC_DATA_TREES = \"5rq2-4hqu.json\"\n",
    "\n",
    "DB_NAME = \"Project4501\"\n",
    "DB_USER = \"postgres\"\n",
    "DB_PASSWORD = \"727403\"\n",
    "DB_HOST = 'localhost'\n",
    "DB_URL=f'postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}/{DB_NAME}'\n",
    "DB_SCHEMA_FILE = \"schema.sql\"\n",
    "\n",
    "crs='EPSG:4326'\n",
    "\n",
    "rent_month_dict = {}\n",
    "# directory where DB queries for Part 3 will be saved\n",
    "QUERY_DIR = pathlib.Path(\"queries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd67cca9-ec72-44e3-83b8-b65f1ed5bb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the QUERY_DIRECTORY exists\n",
    "if not QUERY_DIR.exists():\n",
    "    QUERY_DIR.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52476a07-9bf2-4b7a-8cb7-93648bb4d303",
   "metadata": {},
   "source": [
    "## Part 1: Data Preprocessing\n",
    "\n",
    "Four Dataset is downloaded and cleaned for part 1, they are NYC_311, NYC_ZILLOW, ZIPCODE and NYC_TREES\n",
    "Here are some descriptions of the datasets:\n",
    "\n",
    "1. `NYC_311` is the downloaded data where the 311 requests come from, we use the application token generated to download the data, since the whole data file is too large, we set a limit equals to 700000 and use `soql` command to store it in 30 JSON files. Through this we downloaded 1380551 data from the whole dataset as a population sample for this project.\n",
    "\n",
    "2. `NYC_TREE` is the downloaded data from the tree census part, we adopt a similar method here, set a limit of 700000, but without the use of 30 JSON files, we got 683788 data here as a population sample for this project.\n",
    "\n",
    "3. `NYC_ZILLOW` is the manually downloaded data from the shared Google file, which includes the historical monthly average rents by zip code from Zillow, we only keep the `zipcode`, `recorded_date` and `rent` variable as they are the only needed data for analysis in part 3 and part 4.\n",
    "\n",
    "4. `NYC_ZIPCODE` is the manually downloaded data from the shared Google file, which includes the `shp` file for the geometry boundary of New York City."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c9e64b",
   "metadata": {},
   "source": [
    "### Download of NYC_311 request data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63b18f12-c0ce-4b9c-adc1-805703edc575",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_nyc_311_data(url, force=False):\n",
    "    json_files = [f\"{i}.json\" for i in range(30)]\n",
    "    filenames = [COMPLAINTS_DATE_DIR / i for i in json_files ]\n",
    "    \n",
    "    if not COMPLAINTS_DATE_DIR.exists():\n",
    "        COMPLAINTS_DATE_DIR.mkdir()\n",
    "    \n",
    "    limit = 700000\n",
    "    for filename in filenames:\n",
    "        if force or not filename.exists():\n",
    "            print(f\"Downloading\")\n",
    "            offset = int(filename.stem) * 700000\n",
    "            all_entries = []\n",
    "            selected_columns = [\"unique_key\", \"created_date\", \"complaint_type\", \"incident_zip\", \"location\"]\n",
    "            soql_query311 = f\"{url}?$$app_token={APP_TOKEN}&$select={','.join(selected_columns)}&$limit={700000}&$offset={offset}\"\n",
    "            response = requests.get(soql_query311)\n",
    "            if response.status_code == 200: \n",
    "                entries = response.json()       \n",
    "        \n",
    "            with open(filename, \"w\") as f:\n",
    "                json.dump(entries, f)\n",
    "            print(f\"Finished download\")\n",
    "            \n",
    "    print(f\"load data from {filenames} to {filenames}...\")\n",
    "    return filenames[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c5a0c7",
   "metadata": {},
   "source": [
    "### Download of NYC_Tree Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "163c13b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_nyc_tree_data(url, force=False):\n",
    "    url_path1 = urllib.parse.urlparse(url).path.split(\"/\")[-1]\n",
    "    filename = DATA_DIR / url_path1\n",
    "    \n",
    "    if not DATA_DIR.exists():\n",
    "        DATA_DIR.mkdir()\n",
    "\n",
    "    if force or not filename.exists():\n",
    "        print(f\"Downloing\")\n",
    "        \n",
    "        limit = 700000\n",
    "        all_entries = []\n",
    "        offset = 0\n",
    "        selected_columns = [\"tree_id\", \"zipcode\", \"the_geom\", \"spc_common\", \"health\", \"status\",\"latitude\", \"longitude\"]\n",
    "        end = 700000\n",
    "        \n",
    "        while offset < end:  \n",
    "            total = limit+offset\n",
    "            print(f\"start from {offset} while total is {total}\")\n",
    "            soql_querytree = f\"{url}?$$app_token={APP_TOKEN}&$select={','.join(selected_columns)}&$limit=700000&$offset={offset}\"\n",
    "            response = requests.get(soql_querytree)\n",
    "            if response.status_code == 200: \n",
    "                entries = response.json()\n",
    "                all_entries.extend(entries)\n",
    "                offset += limit\n",
    "                  \n",
    "        with open(filename, \"w\") as f:\n",
    "            json.dump(all_entries, f)\n",
    "        print(f\"Finished download\")\n",
    "\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a744f0c",
   "metadata": {},
   "source": [
    "### Load and clean of the zipcode data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ee245240-2fbb-45b8-9a92-4e2368f62c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_zipcodes(zipcode_datafile):\n",
    "    global unique_zipcodes\n",
    "    gdf = gpd.read_file(zipcode_datafile).to_crs(epsg=4326)\n",
    "    unique_zipcodes_df = gdf[[\"ZIPCODE\", \"geometry\"]].drop_duplicates(subset=\"ZIPCODE\").reset_index(drop=True)\n",
    "    unique_zipcodes = unique_zipcodes_df[\"ZIPCODE\"]\n",
    "\n",
    "    return unique_zipcodes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c59f5b",
   "metadata": {},
   "source": [
    "### Download and clean of the 311 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "562d23f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_clean_311_data():\n",
    "    filenames = download_nyc_311_data(f\"{BASE_NYC_DATA_URL}{NYC_DATA_311}\")\n",
    "    processed_frames = []\n",
    "\n",
    "    for filename in filenames:\n",
    "        df = pd.read_json(filename, dtype=\"object\")\n",
    "        \n",
    "        if \"location\" in df.columns:\n",
    "            # Extract latitude and longitude\n",
    "            df[\"latitude\"] = df[\"location\"].apply(lambda x: x.get(\"latitude\") if isinstance(x, dict) else None)\n",
    "            df[\"longitude\"] = df[\"location\"].apply(lambda x: x.get(\"longitude\") if isinstance(x, dict) else None)\n",
    "            \n",
    "            # Create geometry for valid lat-long pairs\n",
    "            df[\"geometry\"] = [\n",
    "                Point(float(lon), float(lat)) if pd.notna(lon) and pd.notna(lat) else None \n",
    "                for lat, lon in zip(df[\"latitude\"], df[\"longitude\"])\n",
    "            ]\n",
    "\n",
    "            # Drop unnecessary columns\n",
    "            df.drop(columns=[\"location\", \"longitude\", \"latitude\"], inplace=True)\n",
    "\n",
    "            # Filter by incident zip and unique zipcodes\n",
    "            df = df[pd.notna(df[\"incident_zip\"]) & df[\"incident_zip\"].isin(unique_zipcodes)]\n",
    "\n",
    "            # Create a GeoDataFrame\n",
    "            gdf = gpd.GeoDataFrame(df, geometry=\"geometry\")\n",
    "            gdf.crs = \"EPSG:4326\"\n",
    "            \n",
    "            processed_frames.append(gdf)\n",
    "\n",
    "    # Concatenate all GeoDataFrames\n",
    "    final_gdf = gpd.GeoDataFrame(pd.concat(processed_frames, ignore_index=True, sort=False)).drop_duplicates(subset=['unique_key']).reset_index(drop=True)\n",
    "    return final_gdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfaf4a2",
   "metadata": {},
   "source": [
    "### Download and clean of the tree data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "39c4b1bc-c841-4b87-8301-1dc2cafeccc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_clean_tree_data():\n",
    "    filename = download_nyc_tree_data(f\"{BASE_NYC_DATA_URL}{NYC_DATA_TREES}\")\n",
    "    tree_df = pd.read_json(filename, dtype='object')\n",
    "\n",
    "    tree_df[\"geometry\"] = tree_df[\"the_geom\"].apply(lambda x: Point(x[\"coordinates\"]) if x[\"coordinates\"] else None)\n",
    "    tree_df.drop(columns=[\"the_geom\"], inplace=True)\n",
    "\n",
    "    # Define the dtype conversion dictionary\n",
    "    convert_dict = {\n",
    "        \"tree_id\": int,\n",
    "        \"spc_common\": str,\n",
    "        \"health\": str,\n",
    "        \"status\": str,\n",
    "        \"zipcode\": str,\n",
    "        \"geometry\": \"geometry\"  # Ensure geometry is identified for GeoDataFrame\n",
    "    }\n",
    "\n",
    "    # Convert dtypes and filter by zipcodes\n",
    "    tree_gdf_normalized = gpd.GeoDataFrame(tree_df.astype(convert_dict))\n",
    "    tree_gdf_normalized = tree_gdf_normalized[tree_gdf_normalized[\"zipcode\"].isin(unique_zipcodes)]\n",
    "\n",
    "    # Set the coordinate reference system\n",
    "    tree_gdf_normalized.set_crs(epsg=4326, inplace=True)\n",
    "\n",
    "    return tree_gdf_normalized\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59168e42",
   "metadata": {},
   "source": [
    "### Load and clean of the Zillow Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "577c7bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_zillow_data(zillow_datafile):\n",
    "    data = pd.read_csv(zillow_datafile)\n",
    "    \n",
    "    zillow_data_NY = data[data.City == \"New York\"]\n",
    "    numeric_columns = data.filter(regex=\"^\\d\").columns.tolist()\n",
    "    zillow_NY_dataset = zillow_data_NY[[\"RegionName\"] + numeric_columns]\n",
    "    zillow_NY_dataset_halfclean = pd.melt(zillow_NY_dataset, id_vars=[\"RegionName\"], var_name=\"recorded_date\", value_name=\"rent\")\n",
    "    zillow_NY_dataset_clean = zillow_NY_dataset_halfclean.dropna(subset=[\"rent\"])\n",
    "    \n",
    "    zillow_NY_dataset_clean = zillow_NY_dataset_clean.rename(columns={\"RegionName\": \"zipcode\"})\n",
    "    zillow_NY_dataset_clean[\"recorded_date\"] = pd.to_datetime(zillow_NY_dataset_clean[\"recorded_date\"])\n",
    "    \n",
    "    return zillow_NY_dataset_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "345ebc2c-14f1-490c-9857-11f1e332e3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_data():\n",
    "    df_zillow_data = load_and_clean_zillow_data(ZILLOW_DATA_FILE)\n",
    "    geodf_zipcode_data = load_and_clean_zipcodes(ZIPCODE_DATA_FILE)\n",
    "    geodf_311_data = download_and_clean_311_data()\n",
    "    geodf_tree_data = download_and_clean_tree_data()\n",
    "    return (\n",
    "        geodf_zipcode_data,\n",
    "        geodf_311_data,\n",
    "        geodf_tree_data,\n",
    "        df_zillow_data       \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9c18f578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data from [PosixPath('data/311_data/0.json'), PosixPath('data/311_data/1.json'), PosixPath('data/311_data/2.json'), PosixPath('data/311_data/3.json'), PosixPath('data/311_data/4.json'), PosixPath('data/311_data/5.json'), PosixPath('data/311_data/6.json'), PosixPath('data/311_data/7.json'), PosixPath('data/311_data/8.json'), PosixPath('data/311_data/9.json'), PosixPath('data/311_data/10.json'), PosixPath('data/311_data/11.json'), PosixPath('data/311_data/12.json'), PosixPath('data/311_data/13.json'), PosixPath('data/311_data/14.json'), PosixPath('data/311_data/15.json'), PosixPath('data/311_data/16.json'), PosixPath('data/311_data/17.json'), PosixPath('data/311_data/18.json'), PosixPath('data/311_data/19.json'), PosixPath('data/311_data/20.json'), PosixPath('data/311_data/21.json'), PosixPath('data/311_data/22.json'), PosixPath('data/311_data/23.json'), PosixPath('data/311_data/24.json'), PosixPath('data/311_data/25.json'), PosixPath('data/311_data/26.json'), PosixPath('data/311_data/27.json'), PosixPath('data/311_data/28.json'), PosixPath('data/311_data/29.json')] to [PosixPath('data/311_data/0.json'), PosixPath('data/311_data/1.json'), PosixPath('data/311_data/2.json'), PosixPath('data/311_data/3.json'), PosixPath('data/311_data/4.json'), PosixPath('data/311_data/5.json'), PosixPath('data/311_data/6.json'), PosixPath('data/311_data/7.json'), PosixPath('data/311_data/8.json'), PosixPath('data/311_data/9.json'), PosixPath('data/311_data/10.json'), PosixPath('data/311_data/11.json'), PosixPath('data/311_data/12.json'), PosixPath('data/311_data/13.json'), PosixPath('data/311_data/14.json'), PosixPath('data/311_data/15.json'), PosixPath('data/311_data/16.json'), PosixPath('data/311_data/17.json'), PosixPath('data/311_data/18.json'), PosixPath('data/311_data/19.json'), PosixPath('data/311_data/20.json'), PosixPath('data/311_data/21.json'), PosixPath('data/311_data/22.json'), PosixPath('data/311_data/23.json'), PosixPath('data/311_data/24.json'), PosixPath('data/311_data/25.json'), PosixPath('data/311_data/26.json'), PosixPath('data/311_data/27.json'), PosixPath('data/311_data/28.json'), PosixPath('data/311_data/29.json')]...\n"
     ]
    }
   ],
   "source": [
    "geodf_zipcode_data, geodf_311_data, geodf_tree_data, df_zillow_data = load_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "23ad8bbc-bf91-457e-97db-a945fabeee29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 248 entries, 0 to 247\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype   \n",
      "---  ------    --------------  -----   \n",
      " 0   ZIPCODE   248 non-null    object  \n",
      " 1   geometry  248 non-null    geometry\n",
      "dtypes: geometry(1), object(1)\n",
      "memory usage: 4.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Show basic info about each dataframe\n",
    "geodf_zipcode_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ec68f4be-f365-46c1-91a1-ab75deb75ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ZIPCODE</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11436</td>\n",
       "      <td>POLYGON ((-73.80585 40.68291, -73.80569 40.682...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11213</td>\n",
       "      <td>POLYGON ((-73.93740 40.67973, -73.93487 40.679...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11212</td>\n",
       "      <td>POLYGON ((-73.90294 40.67084, -73.90223 40.668...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11225</td>\n",
       "      <td>POLYGON ((-73.95797 40.67066, -73.95576 40.670...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11218</td>\n",
       "      <td>POLYGON ((-73.97208 40.65060, -73.97192 40.650...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ZIPCODE                                           geometry\n",
       "0   11436  POLYGON ((-73.80585 40.68291, -73.80569 40.682...\n",
       "1   11213  POLYGON ((-73.93740 40.67973, -73.93487 40.679...\n",
       "2   11212  POLYGON ((-73.90294 40.67084, -73.90223 40.668...\n",
       "3   11225  POLYGON ((-73.95797 40.67066, -73.95576 40.670...\n",
       "4   11218  POLYGON ((-73.97208 40.65060, -73.97192 40.650..."
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show first 5 entries about each dataframe\n",
    "geodf_zipcode_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6a803b68-2f07-44b8-8b24-d4f16c9e03fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 1380552 entries, 0 to 1380551\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count    Dtype   \n",
      "---  ------          --------------    -----   \n",
      " 0   unique_key      1380552 non-null  object  \n",
      " 1   created_date    1380552 non-null  object  \n",
      " 2   complaint_type  1380552 non-null  object  \n",
      " 3   incident_zip    1380552 non-null  object  \n",
      " 4   geometry        1368209 non-null  geometry\n",
      "dtypes: geometry(1), object(4)\n",
      "memory usage: 52.7+ MB\n"
     ]
    }
   ],
   "source": [
    "geodf_311_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "14705df9-ea77-4d57-ac8e-1845f80a216d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_key</th>\n",
       "      <th>created_date</th>\n",
       "      <th>complaint_type</th>\n",
       "      <th>incident_zip</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59596685</td>\n",
       "      <td>2023-12-01T12:00:00.000</td>\n",
       "      <td>Derelict Vehicles</td>\n",
       "      <td>10465</td>\n",
       "      <td>POINT (-73.82455 40.84384)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59602215</td>\n",
       "      <td>2023-12-01T01:03:37.000</td>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>10308</td>\n",
       "      <td>POINT (-74.15722 40.56203)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59599429</td>\n",
       "      <td>2023-12-01T01:03:29.000</td>\n",
       "      <td>Noise - Vehicle</td>\n",
       "      <td>11207</td>\n",
       "      <td>POINT (-73.90681 40.68472)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59598012</td>\n",
       "      <td>2023-12-01T01:03:27.000</td>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>10467</td>\n",
       "      <td>POINT (-73.86698 40.87631)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59598087</td>\n",
       "      <td>2023-12-01T01:03:20.000</td>\n",
       "      <td>Encampment</td>\n",
       "      <td>10024</td>\n",
       "      <td>POINT (-73.97900 40.78516)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  unique_key             created_date       complaint_type incident_zip  \\\n",
       "0   59596685  2023-12-01T12:00:00.000    Derelict Vehicles        10465   \n",
       "1   59602215  2023-12-01T01:03:37.000  Noise - Residential        10308   \n",
       "2   59599429  2023-12-01T01:03:29.000      Noise - Vehicle        11207   \n",
       "3   59598012  2023-12-01T01:03:27.000  Noise - Residential        10467   \n",
       "4   59598087  2023-12-01T01:03:20.000           Encampment        10024   \n",
       "\n",
       "                     geometry  \n",
       "0  POINT (-73.82455 40.84384)  \n",
       "1  POINT (-74.15722 40.56203)  \n",
       "2  POINT (-73.90681 40.68472)  \n",
       "3  POINT (-73.86698 40.87631)  \n",
       "4  POINT (-73.97900 40.78516)  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geodf_311_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e6006cd2-3a00-4660-8d2a-a660b9bfd91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "Int64Index: 683788 entries, 0 to 683787\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count   Dtype   \n",
      "---  ------      --------------   -----   \n",
      " 0   tree_id     683788 non-null  int64   \n",
      " 1   zipcode     683788 non-null  object  \n",
      " 2   spc_common  683788 non-null  object  \n",
      " 3   health      683788 non-null  object  \n",
      " 4   status      683788 non-null  object  \n",
      " 5   latitude    683788 non-null  object  \n",
      " 6   longitude   683788 non-null  object  \n",
      " 7   geometry    683788 non-null  geometry\n",
      "dtypes: geometry(1), int64(1), object(6)\n",
      "memory usage: 47.0+ MB\n"
     ]
    }
   ],
   "source": [
    "geodf_tree_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "07f880ef-c5fc-4159-8174-21ccd44f492d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tree_id</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>spc_common</th>\n",
       "      <th>health</th>\n",
       "      <th>status</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>180683</td>\n",
       "      <td>11375</td>\n",
       "      <td>red maple</td>\n",
       "      <td>Fair</td>\n",
       "      <td>Alive</td>\n",
       "      <td>40.72309177</td>\n",
       "      <td>-73.84421522</td>\n",
       "      <td>POINT (-73.84422 40.72309)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200540</td>\n",
       "      <td>11357</td>\n",
       "      <td>pin oak</td>\n",
       "      <td>Fair</td>\n",
       "      <td>Alive</td>\n",
       "      <td>40.79411067</td>\n",
       "      <td>-73.81867946</td>\n",
       "      <td>POINT (-73.81868 40.79411)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>204026</td>\n",
       "      <td>11211</td>\n",
       "      <td>honeylocust</td>\n",
       "      <td>Good</td>\n",
       "      <td>Alive</td>\n",
       "      <td>40.71758074</td>\n",
       "      <td>-73.9366077</td>\n",
       "      <td>POINT (-73.93661 40.71758)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>204337</td>\n",
       "      <td>11211</td>\n",
       "      <td>honeylocust</td>\n",
       "      <td>Good</td>\n",
       "      <td>Alive</td>\n",
       "      <td>40.71353749</td>\n",
       "      <td>-73.93445616</td>\n",
       "      <td>POINT (-73.93446 40.71354)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>189565</td>\n",
       "      <td>11215</td>\n",
       "      <td>American linden</td>\n",
       "      <td>Good</td>\n",
       "      <td>Alive</td>\n",
       "      <td>40.66677776</td>\n",
       "      <td>-73.97597938</td>\n",
       "      <td>POINT (-73.97598 40.66678)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tree_id zipcode       spc_common health status     latitude     longitude  \\\n",
       "0   180683   11375        red maple   Fair  Alive  40.72309177  -73.84421522   \n",
       "1   200540   11357          pin oak   Fair  Alive  40.79411067  -73.81867946   \n",
       "2   204026   11211      honeylocust   Good  Alive  40.71758074   -73.9366077   \n",
       "3   204337   11211      honeylocust   Good  Alive  40.71353749  -73.93445616   \n",
       "4   189565   11215  American linden   Good  Alive  40.66677776  -73.97597938   \n",
       "\n",
       "                     geometry  \n",
       "0  POINT (-73.84422 40.72309)  \n",
       "1  POINT (-73.81868 40.79411)  \n",
       "2  POINT (-73.93661 40.71758)  \n",
       "3  POINT (-73.93446 40.71354)  \n",
       "4  POINT (-73.97598 40.66678)  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geodf_tree_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "59724f74-5f1e-435c-b843-f381a875dd4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9039 entries, 5 to 15224\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   zipcode        9039 non-null   int64         \n",
      " 1   recorded_date  9039 non-null   datetime64[ns]\n",
      " 2   rent           9039 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(1), int64(1)\n",
      "memory usage: 282.5 KB\n"
     ]
    }
   ],
   "source": [
    "df_zillow_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e29ae5d9-9768-4590-a2f2-dd63b07dd712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zipcode</th>\n",
       "      <th>recorded_date</th>\n",
       "      <th>rent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11226</td>\n",
       "      <td>2015-01-31</td>\n",
       "      <td>1944.609891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10025</td>\n",
       "      <td>2015-01-31</td>\n",
       "      <td>3068.951823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11206</td>\n",
       "      <td>2015-01-31</td>\n",
       "      <td>2482.829299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11221</td>\n",
       "      <td>2015-01-31</td>\n",
       "      <td>2125.738807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>11235</td>\n",
       "      <td>2015-01-31</td>\n",
       "      <td>1687.789898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    zipcode recorded_date         rent\n",
       "5     11226    2015-01-31  1944.609891\n",
       "7     10025    2015-01-31  3068.951823\n",
       "13    11206    2015-01-31  2482.829299\n",
       "14    11221    2015-01-31  2125.738807\n",
       "20    11235    2015-01-31  1687.789898"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zillow_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e685942c-26dc-40db-84c2-a71aa3340806",
   "metadata": {},
   "source": [
    "## Part 2: Storing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e2d2c50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "createdb: error: database creation failed: ERROR:  database \"Project4501\" already exists\r\n"
     ]
    }
   ],
   "source": [
    "## first step: create database 'Project4501'in PostgreSQL\n",
    "!createdb Project4501"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0f917517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:  extension \"postgis\" already exists\r\n"
     ]
    }
   ],
   "source": [
    "!psql --dbname Project4501 -c 'CREATE EXTENSION postgis;'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae3f9bd",
   "metadata": {},
   "source": [
    "### Creating Tables\n",
    "\n",
    "\n",
    "These are just a couple of options to creating your tables; you can use one or the other, a different method, or a combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e185aa4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tables(engine):\n",
    "    metadata = MetaData()\n",
    "\n",
    "    nyc_311 = Table(\n",
    "        'nyc_311', metadata,\n",
    "        Column('unique_key', Integer, primary_key=True),\n",
    "        Column('created_date', TIMESTAMP),\n",
    "        Column('complaint_type', String),\n",
    "        Column('incident_zip', Integer),\n",
    "        Column('geometry', Geometry('POINT', srid=4326))\n",
    "    )\n",
    "\n",
    "    nyc_tree = Table(\n",
    "        'nyc_tree', metadata,\n",
    "        Column('tree_id', Integer, primary_key=True),\n",
    "        Column('status', String),\n",
    "        Column('health', String),\n",
    "        Column('spc_common', String),\n",
    "        Column('zipcode', Integer),\n",
    "        Column('geometry', Geometry('POINT', srid=4326))\n",
    "    )\n",
    "\n",
    "    nyc_zipcode = Table(\n",
    "        'nyc_zipcode', metadata,\n",
    "        Column('zipcode', Integer, primary_key=True),\n",
    "        Column('geometry', Geometry('POLYGON', srid=4326))\n",
    "    )\n",
    "    \n",
    "    nyc_zillow = Table(\n",
    "        'nyc_zillow', metadata,\n",
    "        Column('zipcode', Integer, primary_key=True),\n",
    "        Column('recorded_date', Date),\n",
    "        Column('rent', Float)\n",
    "    )\n",
    "\n",
    "    metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "daa0e4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_indexes(connection):\n",
    "    sql_create_indexes = \"\"\"\n",
    "    CREATE INDEX IF NOT EXISTS idx_nyc_311_location ON \"nyc_311\" USING gist (geometry);\n",
    "    CREATE INDEX IF NOT EXISTS idx_nyc_tree_location ON \"nyc_tree\" USING gist (geometry);\n",
    "    CREATE INDEX IF NOT EXISTS idx_nyc_zipcode_location ON \"nyc_zipcode\" USING gist (geometry);\n",
    "    \"\"\"\n",
    "\n",
    "    with connection.cursor() as cursor:\n",
    "        cursor.execute(sql_create_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cc5d7819",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "engine = create_engine(DB_URL)\n",
    "create_tables(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9c77f379",
   "metadata": {},
   "outputs": [],
   "source": [
    "with psycopg2.connect(DB_URL) as connection:\n",
    "    create_indexes(connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e88a50c-9528-4a5c-9a52-b96781ee8985",
   "metadata": {},
   "source": [
    "### Add Data to Database using SQLAlchemy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2d2cbf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dataframes_to_table(df_name, table_name):\n",
    "    engine = create_engine(DB_URL)\n",
    "    try:\n",
    "        df_name.to_postgis(table_name, engine, if_exists='replace', index=False)\n",
    "    except:\n",
    "        df_name.to_sql(table_name, engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1427ac37",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dataframes_to_table(geodf_311_data, 'nyc_311')\n",
    "write_dataframes_to_table(geodf_tree_data, 'nyc_tree')\n",
    "write_dataframes_to_table(geodf_zipcode_data,\"nyc_zipcode\")\n",
    "write_dataframes_to_table(df_zillow_data,\"nyc_zillow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d579c5",
   "metadata": {},
   "source": [
    "## Part 3: Understanding the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b506ce",
   "metadata": {},
   "source": [
    "### Query 1\n",
    "\n",
    "Query 1: Which area might be more calm to live in?\n",
    "Between October 1st, 2022 and September 30th, 2023 (inclusive), find the number of 311 complaints per zip code. \n",
    "\n",
    "The query result should have two columns, one row per zip code, with the number of complaints in descending order.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "026ecc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to write the queries to file\n",
    "def write_query_to_file(query, outfile):\n",
    "    with open(outfile, 'w') as file:\n",
    "        file.write(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "134861e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_1_FILENAME = QUERY_DIR / \"top_zipcodes_with311complaints_noise.sql\"\n",
    "\n",
    "QUERY_1 = \"\"\"\n",
    "SELECT \n",
    "      incident_zip, \n",
    "      COUNT(*) AS complaint_count\n",
    "FROM \n",
    "      nyc_311\n",
    "WHERE \n",
    "      created_date BETWEEN '2022-10-01' AND '2023-09-30'\n",
    "      AND complaint_type LIKE '%Noise%'\n",
    "GROUP BY \n",
    "      incident_zip\n",
    "ORDER BY \n",
    "      complaint_count DESC;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e201c569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zip Code ｜ Complaint Count\n",
      "10456｜4267\n",
      "10457｜3914\n",
      "10452｜3630\n",
      "10453｜3506\n",
      "10031｜3500\n",
      "10023｜3338\n",
      "10032｜3235\n",
      "11226｜2968\n",
      "11221｜2714\n",
      "10468｜2709\n",
      "10458｜2687\n",
      "11414｜2555\n",
      "11207｜2485\n",
      "11208｜2223\n",
      "10025｜2213\n",
      "10466｜2200\n",
      "11201｜2194\n",
      "11368｜2154\n",
      "10002｜2108\n",
      "10467｜2068\n",
      "11237｜2059\n",
      "11216｜2055\n",
      "10034｜2025\n",
      "10026｜2015\n",
      "11385｜1873\n",
      "10460｜1872\n",
      "10027｜1848\n",
      "10009｜1830\n",
      "11419｜1809\n",
      "10040｜1764\n",
      "11206｜1737\n",
      "10033｜1728\n",
      "11212｜1720\n",
      "11238｜1631\n",
      "11433｜1567\n",
      "11211｜1567\n",
      "10472｜1559\n",
      "11101｜1545\n",
      "10029｜1542\n",
      "10463｜1539\n",
      "11225｜1535\n",
      "11233｜1456\n",
      "11420｜1433\n",
      "11203｜1421\n",
      "11377｜1341\n",
      "10030｜1323\n",
      "10455｜1308\n",
      "10459｜1307\n",
      "11373｜1289\n",
      "10462｜1254\n",
      "11249｜1236\n",
      "10451｜1235\n",
      "11220｜1228\n",
      "11213｜1188\n",
      "11375｜1166\n",
      "11372｜1124\n",
      "11434｜1109\n",
      "10003｜1100\n",
      "10016｜1081\n",
      "10469｜1076\n",
      "11224｜1066\n",
      "11234｜1021\n",
      "11435｜1019\n",
      "10019｜1012\n",
      "10473｜1003\n",
      "11222｜977\n",
      "11229｜967\n",
      "11236｜955\n",
      "10454｜941\n",
      "10011｜917\n",
      "11217｜890\n",
      "11235｜889\n",
      "10035｜887\n",
      "11209｜879\n",
      "11103｜863\n",
      "10036｜860\n",
      "11691｜831\n",
      "11232｜827\n",
      "11421｜820\n",
      "10465｜808\n",
      "10028｜806\n",
      "10039｜806\n",
      "10001｜800\n",
      "11106｜797\n",
      "11355｜790\n",
      "11223｜745\n",
      "10012｜742\n",
      "10461｜735\n",
      "11357｜731\n",
      "11210｜723\n",
      "10024｜721\n",
      "11231｜709\n",
      "10301｜704\n",
      "11432｜704\n",
      "11436｜667\n",
      "11354｜641\n",
      "11218｜626\n",
      "11215｜626\n",
      "10014｜624\n",
      "11105｜622\n",
      "11417｜618\n",
      "11230｜618\n",
      "10038｜595\n",
      "11214｜573\n",
      "11205｜561\n",
      "11102｜551\n",
      "10013｜541\n",
      "11204｜535\n",
      "10314｜534\n",
      "10128｜516\n",
      "11412｜508\n",
      "11418｜497\n",
      "10037｜494\n",
      "11428｜481\n",
      "10304｜472\n",
      "11413｜437\n",
      "11378｜435\n",
      "11219｜420\n",
      "11694｜420\n",
      "10471｜411\n",
      "11356｜409\n",
      "10010｜408\n",
      "10305｜407\n",
      "11692｜395\n",
      "11366｜393\n",
      "11374｜388\n",
      "10306｜371\n",
      "11411｜360\n",
      "11422｜357\n",
      "11423｜352\n",
      "11365｜343\n",
      "11416｜328\n",
      "10018｜321\n",
      "10021｜315\n",
      "11693｜314\n",
      "11104｜312\n",
      "11369｜308\n",
      "11370｜304\n",
      "11361｜289\n",
      "10470｜286\n",
      "10022｜284\n",
      "11367｜279\n",
      "11429｜278\n",
      "10474｜269\n",
      "10312｜267\n",
      "11358｜266\n",
      "11379｜258\n",
      "11427｜252\n",
      "10310｜233\n",
      "10302｜233\n",
      "10309｜228\n",
      "10065｜226\n",
      "11415｜225\n",
      "10303｜212\n",
      "10017｜197\n",
      "10075｜196\n",
      "11364｜191\n",
      "11228｜190\n",
      "10307｜180\n",
      "10005｜161\n",
      "10004｜160\n",
      "10308｜154\n",
      "11426｜141\n",
      "11360｜137\n",
      "10464｜135\n",
      "11004｜114\n",
      "10475｜104\n",
      "11239｜99\n",
      "10007｜95\n",
      "11109｜74\n",
      "10044｜67\n",
      "10006｜60\n",
      "11362｜54\n",
      "11040｜35\n",
      "11359｜32\n",
      "10280｜24\n",
      "10282｜21\n",
      "10069｜19\n",
      "11363｜16\n",
      "11001｜15\n",
      "11005｜11\n",
      "10120｜9\n",
      "10110｜6\n",
      "10020｜4\n",
      "11697｜4\n",
      "10105｜3\n",
      "11430｜2\n",
      "10281｜2\n",
      "10178｜2\n",
      "10123｜1\n",
      "10278｜1\n",
      "11251｜1\n",
      "10118｜1\n",
      "10172｜1\n",
      "10169｜1\n",
      "10158｜1\n",
      "10154｜1\n",
      "10153｜1\n",
      "10271｜1\n"
     ]
    }
   ],
   "source": [
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(QUERY_1))\n",
    "    print(f\"Zip Code ｜ Complaint Count\")\n",
    "    for row in result:\n",
    "        print(f\"{row.incident_zip}｜{row.complaint_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8463ed1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_1, QUERY_1_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b906c7a2",
   "metadata": {},
   "source": [
    "### Query 2  Where has the most greenery?\n",
    "Using just the trees table, which 10 zip codes have the most trees?\n",
    "\n",
    "The query result should have two columns, 10 rows. The rows should be sorted by the total number of trees, descending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "50f2548d",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_2_FILENAME = QUERY_DIR / \"zipcodes_by_greenery.sql\"\n",
    "\n",
    "QUERY_2 = \"\"\"\n",
    "SELECT \n",
    "     zipcode, \n",
    "     COUNT(*) AS tree_count\n",
    "FROM \n",
    "     nyc_tree\n",
    "WHERE \n",
    "     status = 'Alive'\n",
    "GROUP BY \n",
    "     zipcode\n",
    "ORDER BY \n",
    "     tree_count DESC\n",
    "LIMIT 10;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ee520180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zip Code| Tree Count\n",
      "10312| 21356\n",
      "10314| 16330\n",
      "10306| 12616\n",
      "10309| 12106\n",
      "11234| 10838\n",
      "11385| 10262\n",
      "11357| 9017\n",
      "11207| 8293\n",
      "11208| 7896\n",
      "11434| 7833\n"
     ]
    }
   ],
   "source": [
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(QUERY_2))\n",
    "    print(f\"Zip Code| Tree Count\")\n",
    "    for row in result:\n",
    "        print(f\"{row.zipcode}| {row.tree_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "af911e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_2, QUERY_2_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2123460e",
   "metadata": {},
   "source": [
    "### Query 3 Can I afford a place in the areas with the most trees?\n",
    "Of the 10 zip codes with the most trees, for the month of August 2023, what is the average rent by zip code?\n",
    "\n",
    "The query should have a JOIN statement. The query result should have two columns (not three) and 10 rows. The rows should be sorted by the total number of trees, descending. “Humanize” the rent numbers, meaning format the results as 2,879.58 instead of 2879.575128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "318e1d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_3_FILENAME = QUERY_DIR / \"average_rent_in_mosttree_zipcodes.sql\"\n",
    "\n",
    "QUERY_3 = \"\"\"\n",
    "\n",
    "SELECT \n",
    "    t.zipcode, \n",
    "    TO_CHAR(AVG(z.rent), 'FM9,999.99') as average_rent\n",
    "FROM \n",
    "    (\n",
    "        SELECT \n",
    "            CAST(zipcode AS text), -- Cast to text if needed\n",
    "            COUNT(*) AS tree_count\n",
    "        FROM \n",
    "            nyc_tree\n",
    "        WHERE \n",
    "            status = 'Alive'\n",
    "        GROUP BY \n",
    "            zipcode\n",
    "        ORDER BY \n",
    "            COUNT(*) DESC\n",
    "        LIMIT 10\n",
    "    ) AS t\n",
    "JOIN \n",
    "    nyc_zillow z ON t.zipcode = CAST(z.zipcode AS text) -- Cast to text if needed\n",
    "WHERE \n",
    "    z.recorded_date BETWEEN '2023-08-01' AND '2023-08-31'\n",
    "GROUP BY \n",
    "    t.zipcode, t.tree_count\n",
    "ORDER BY \n",
    "    average_rent DESC\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b125c7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zip Code| Average Rent\n",
      "11207| 3,079.09\n",
      "11385| 3,064.48\n",
      "11208| 2,737.55\n",
      "11434| 2,645.92\n",
      "10314| 2,465.47\n",
      "11357| 2,458.81\n",
      "10306| 2,331.54\n",
      "11234| 2,312.31\n",
      "10309| 1,832.01\n",
      "10312| 1,775.09\n"
     ]
    }
   ],
   "source": [
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(QUERY_3))\n",
    "    print(f\"Zip Code| Average Rent\")\n",
    "    for row in result:\n",
    "        print(f\"{row.zipcode}| {row.average_rent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c2b9e912",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_3, QUERY_3_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec30d2f",
   "metadata": {},
   "source": [
    "### Query 4 Could there be a correlation between an area’s rent, the number of its trees, and the number of 311 complaints?\n",
    "For the month of January 2023, return the 5 zip codes with the lowest average rent, and 5 zipcodes of the highest average rent, and include the tree count and complaint count for each zip code by using JOIN statements.\n",
    "\n",
    "The query result should have 4 columns (zip code, average rent, tree count, and complaint count) and 10 rows: five with the highest average rent, and five with the lowest average rent. “Humanize” the rent numbers, meaning format the results as 2,879.58 instead of 2879.575128.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b318c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
